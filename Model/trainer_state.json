{
  "best_global_step": 3778,
  "best_metric": 0.870345841252772,
  "best_model_checkpoint": "./results/FacebookAI_xlm-roberta-large/checkpoint-3778",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 3778,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026469031233456855,
      "grad_norm": 7.074739456176758,
      "learning_rate": 8.641975308641976e-07,
      "loss": 0.7057,
      "step": 50
    },
    {
      "epoch": 0.05293806246691371,
      "grad_norm": 4.570083141326904,
      "learning_rate": 1.746031746031746e-06,
      "loss": 0.7004,
      "step": 100
    },
    {
      "epoch": 0.07940709370037057,
      "grad_norm": 8.295280456542969,
      "learning_rate": 2.6278659611992945e-06,
      "loss": 0.6934,
      "step": 150
    },
    {
      "epoch": 0.10587612493382742,
      "grad_norm": 6.113154411315918,
      "learning_rate": 3.509700176366843e-06,
      "loss": 0.6929,
      "step": 200
    },
    {
      "epoch": 0.1323451561672843,
      "grad_norm": Infinity,
      "learning_rate": 4.3915343915343915e-06,
      "loss": 0.6861,
      "step": 250
    },
    {
      "epoch": 0.15881418740074113,
      "grad_norm": 11.791668891906738,
      "learning_rate": 5.2733686067019405e-06,
      "loss": 0.6609,
      "step": 300
    },
    {
      "epoch": 0.185283218634198,
      "grad_norm": 10.025238037109375,
      "learning_rate": 6.155202821869489e-06,
      "loss": 0.541,
      "step": 350
    },
    {
      "epoch": 0.21175224986765484,
      "grad_norm": 63.70779800415039,
      "learning_rate": 7.0370370370370375e-06,
      "loss": 0.4901,
      "step": 400
    },
    {
      "epoch": 0.2382212811011117,
      "grad_norm": 23.99696159362793,
      "learning_rate": 7.918871252204586e-06,
      "loss": 0.3587,
      "step": 450
    },
    {
      "epoch": 0.2646903123345686,
      "grad_norm": 51.40627670288086,
      "learning_rate": 8.800705467372135e-06,
      "loss": 0.3132,
      "step": 500
    },
    {
      "epoch": 0.2911593435680254,
      "grad_norm": 37.79813003540039,
      "learning_rate": 9.682539682539683e-06,
      "loss": 0.296,
      "step": 550
    },
    {
      "epoch": 0.31762837480148226,
      "grad_norm": 17.335275650024414,
      "learning_rate": 9.937254901960786e-06,
      "loss": 0.3195,
      "step": 600
    },
    {
      "epoch": 0.3440974060349391,
      "grad_norm": 33.865013122558594,
      "learning_rate": 9.83921568627451e-06,
      "loss": 0.3168,
      "step": 650
    },
    {
      "epoch": 0.370566437268396,
      "grad_norm": 37.15896224975586,
      "learning_rate": 9.741176470588236e-06,
      "loss": 0.2784,
      "step": 700
    },
    {
      "epoch": 0.39703546850185284,
      "grad_norm": 3.260683059692383,
      "learning_rate": 9.643137254901962e-06,
      "loss": 0.2977,
      "step": 750
    },
    {
      "epoch": 0.4235044997353097,
      "grad_norm": 2.638903856277466,
      "learning_rate": 9.545098039215686e-06,
      "loss": 0.265,
      "step": 800
    },
    {
      "epoch": 0.4499735309687665,
      "grad_norm": 23.390119552612305,
      "learning_rate": 9.447058823529412e-06,
      "loss": 0.314,
      "step": 850
    },
    {
      "epoch": 0.4764425622022234,
      "grad_norm": 20.10052490234375,
      "learning_rate": 9.349019607843139e-06,
      "loss": 0.2498,
      "step": 900
    },
    {
      "epoch": 0.5029115934356803,
      "grad_norm": 176.74234008789062,
      "learning_rate": 9.250980392156863e-06,
      "loss": 0.261,
      "step": 950
    },
    {
      "epoch": 0.5293806246691372,
      "grad_norm": 36.91278839111328,
      "learning_rate": 9.152941176470589e-06,
      "loss": 0.2408,
      "step": 1000
    },
    {
      "epoch": 0.5558496559025939,
      "grad_norm": 3.7363603115081787,
      "learning_rate": 9.054901960784315e-06,
      "loss": 0.2048,
      "step": 1050
    },
    {
      "epoch": 0.5823186871360508,
      "grad_norm": 32.420005798339844,
      "learning_rate": 8.95686274509804e-06,
      "loss": 0.2956,
      "step": 1100
    },
    {
      "epoch": 0.6087877183695076,
      "grad_norm": 11.227447509765625,
      "learning_rate": 8.858823529411765e-06,
      "loss": 0.2494,
      "step": 1150
    },
    {
      "epoch": 0.6352567496029645,
      "grad_norm": 42.883636474609375,
      "learning_rate": 8.760784313725492e-06,
      "loss": 0.2511,
      "step": 1200
    },
    {
      "epoch": 0.6617257808364214,
      "grad_norm": 21.567581176757812,
      "learning_rate": 8.662745098039218e-06,
      "loss": 0.2404,
      "step": 1250
    },
    {
      "epoch": 0.6881948120698782,
      "grad_norm": 28.137989044189453,
      "learning_rate": 8.564705882352942e-06,
      "loss": 0.2554,
      "step": 1300
    },
    {
      "epoch": 0.7146638433033351,
      "grad_norm": 27.27927589416504,
      "learning_rate": 8.466666666666668e-06,
      "loss": 0.1952,
      "step": 1350
    },
    {
      "epoch": 0.741132874536792,
      "grad_norm": 25.178422927856445,
      "learning_rate": 8.368627450980394e-06,
      "loss": 0.3061,
      "step": 1400
    },
    {
      "epoch": 0.7676019057702488,
      "grad_norm": 21.970914840698242,
      "learning_rate": 8.270588235294118e-06,
      "loss": 0.2948,
      "step": 1450
    },
    {
      "epoch": 0.7940709370037057,
      "grad_norm": 16.64971923828125,
      "learning_rate": 8.172549019607845e-06,
      "loss": 0.2389,
      "step": 1500
    },
    {
      "epoch": 0.8205399682371625,
      "grad_norm": 4.445775985717773,
      "learning_rate": 8.074509803921569e-06,
      "loss": 0.2288,
      "step": 1550
    },
    {
      "epoch": 0.8470089994706194,
      "grad_norm": 65.11092376708984,
      "learning_rate": 7.976470588235295e-06,
      "loss": 0.2599,
      "step": 1600
    },
    {
      "epoch": 0.8734780307040763,
      "grad_norm": 22.79574966430664,
      "learning_rate": 7.878431372549021e-06,
      "loss": 0.2572,
      "step": 1650
    },
    {
      "epoch": 0.899947061937533,
      "grad_norm": 23.31258201599121,
      "learning_rate": 7.780392156862745e-06,
      "loss": 0.2031,
      "step": 1700
    },
    {
      "epoch": 0.9264160931709899,
      "grad_norm": 31.431293487548828,
      "learning_rate": 7.682352941176471e-06,
      "loss": 0.2171,
      "step": 1750
    },
    {
      "epoch": 0.9528851244044468,
      "grad_norm": 13.630751609802246,
      "learning_rate": 7.584313725490197e-06,
      "loss": 0.2191,
      "step": 1800
    },
    {
      "epoch": 0.9793541556379036,
      "grad_norm": 21.654634475708008,
      "learning_rate": 7.486274509803923e-06,
      "loss": 0.2438,
      "step": 1850
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8603951890034365,
      "eval_f1": 0.8588187348994265,
      "eval_loss": 0.4139004647731781,
      "eval_precision": 0.8600408063942497,
      "eval_recall": 0.8579311279120054,
      "eval_runtime": 9.3234,
      "eval_samples_per_second": 499.389,
      "eval_steps_per_second": 31.212,
      "step": 1889
    },
    {
      "epoch": 1.0058231868713605,
      "grad_norm": 29.668846130371094,
      "learning_rate": 7.388235294117647e-06,
      "loss": 0.2405,
      "step": 1900
    },
    {
      "epoch": 1.0322922181048173,
      "grad_norm": 2.195927858352661,
      "learning_rate": 7.290196078431373e-06,
      "loss": 0.1436,
      "step": 1950
    },
    {
      "epoch": 1.0587612493382743,
      "grad_norm": 0.5335059762001038,
      "learning_rate": 7.192156862745099e-06,
      "loss": 0.1354,
      "step": 2000
    },
    {
      "epoch": 1.085230280571731,
      "grad_norm": 15.335970878601074,
      "learning_rate": 7.0941176470588245e-06,
      "loss": 0.2597,
      "step": 2050
    },
    {
      "epoch": 1.1116993118051879,
      "grad_norm": 120.85662841796875,
      "learning_rate": 6.99607843137255e-06,
      "loss": 0.1379,
      "step": 2100
    },
    {
      "epoch": 1.138168343038645,
      "grad_norm": 259.14556884765625,
      "learning_rate": 6.898039215686275e-06,
      "loss": 0.2019,
      "step": 2150
    },
    {
      "epoch": 1.1646373742721017,
      "grad_norm": 37.77842712402344,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.2102,
      "step": 2200
    },
    {
      "epoch": 1.1911064055055585,
      "grad_norm": 4.086852550506592,
      "learning_rate": 6.701960784313726e-06,
      "loss": 0.2142,
      "step": 2250
    },
    {
      "epoch": 1.2175754367390152,
      "grad_norm": 29.8253231048584,
      "learning_rate": 6.603921568627451e-06,
      "loss": 0.1978,
      "step": 2300
    },
    {
      "epoch": 1.2440444679724723,
      "grad_norm": 85.3328628540039,
      "learning_rate": 6.5058823529411775e-06,
      "loss": 0.2045,
      "step": 2350
    },
    {
      "epoch": 1.270513499205929,
      "grad_norm": 29.67580795288086,
      "learning_rate": 6.407843137254902e-06,
      "loss": 0.1914,
      "step": 2400
    },
    {
      "epoch": 1.296982530439386,
      "grad_norm": 0.3868177831172943,
      "learning_rate": 6.309803921568628e-06,
      "loss": 0.1598,
      "step": 2450
    },
    {
      "epoch": 1.3234515616728428,
      "grad_norm": 25.20761489868164,
      "learning_rate": 6.211764705882354e-06,
      "loss": 0.2139,
      "step": 2500
    },
    {
      "epoch": 1.3499205929062996,
      "grad_norm": 5.995451927185059,
      "learning_rate": 6.113725490196078e-06,
      "loss": 0.2107,
      "step": 2550
    },
    {
      "epoch": 1.3763896241397564,
      "grad_norm": 0.5339083671569824,
      "learning_rate": 6.015686274509804e-06,
      "loss": 0.1718,
      "step": 2600
    },
    {
      "epoch": 1.4028586553732134,
      "grad_norm": 4.20728063583374,
      "learning_rate": 5.9176470588235305e-06,
      "loss": 0.1881,
      "step": 2650
    },
    {
      "epoch": 1.4293276866066702,
      "grad_norm": 48.469791412353516,
      "learning_rate": 5.819607843137255e-06,
      "loss": 0.1745,
      "step": 2700
    },
    {
      "epoch": 1.455796717840127,
      "grad_norm": 39.6102180480957,
      "learning_rate": 5.721568627450981e-06,
      "loss": 0.1931,
      "step": 2750
    },
    {
      "epoch": 1.482265749073584,
      "grad_norm": 1.6217373609542847,
      "learning_rate": 5.623529411764707e-06,
      "loss": 0.1859,
      "step": 2800
    },
    {
      "epoch": 1.5087347803070408,
      "grad_norm": 14.104793548583984,
      "learning_rate": 5.525490196078431e-06,
      "loss": 0.194,
      "step": 2850
    },
    {
      "epoch": 1.5352038115404976,
      "grad_norm": 44.75010681152344,
      "learning_rate": 5.427450980392157e-06,
      "loss": 0.1314,
      "step": 2900
    },
    {
      "epoch": 1.5616728427739544,
      "grad_norm": 5.791793346405029,
      "learning_rate": 5.329411764705883e-06,
      "loss": 0.2035,
      "step": 2950
    },
    {
      "epoch": 1.5881418740074114,
      "grad_norm": 19.14117431640625,
      "learning_rate": 5.231372549019609e-06,
      "loss": 0.1449,
      "step": 3000
    },
    {
      "epoch": 1.6146109052408681,
      "grad_norm": 48.08278274536133,
      "learning_rate": 5.133333333333334e-06,
      "loss": 0.2078,
      "step": 3050
    },
    {
      "epoch": 1.6410799364743252,
      "grad_norm": 0.2020743191242218,
      "learning_rate": 5.035294117647059e-06,
      "loss": 0.1389,
      "step": 3100
    },
    {
      "epoch": 1.667548967707782,
      "grad_norm": 3.0199134349823,
      "learning_rate": 4.937254901960784e-06,
      "loss": 0.1379,
      "step": 3150
    },
    {
      "epoch": 1.6940179989412387,
      "grad_norm": 72.18175506591797,
      "learning_rate": 4.83921568627451e-06,
      "loss": 0.3078,
      "step": 3200
    },
    {
      "epoch": 1.7204870301746955,
      "grad_norm": 62.32411193847656,
      "learning_rate": 4.741176470588236e-06,
      "loss": 0.1175,
      "step": 3250
    },
    {
      "epoch": 1.7469560614081525,
      "grad_norm": 2.1186182498931885,
      "learning_rate": 4.643137254901961e-06,
      "loss": 0.1956,
      "step": 3300
    },
    {
      "epoch": 1.7734250926416093,
      "grad_norm": 63.834259033203125,
      "learning_rate": 4.545098039215687e-06,
      "loss": 0.2288,
      "step": 3350
    },
    {
      "epoch": 1.7998941238750663,
      "grad_norm": 238.09971618652344,
      "learning_rate": 4.447058823529412e-06,
      "loss": 0.1626,
      "step": 3400
    },
    {
      "epoch": 1.826363155108523,
      "grad_norm": 39.004005432128906,
      "learning_rate": 4.349019607843137e-06,
      "loss": 0.1639,
      "step": 3450
    },
    {
      "epoch": 1.8528321863419799,
      "grad_norm": 9.221044540405273,
      "learning_rate": 4.250980392156863e-06,
      "loss": 0.1657,
      "step": 3500
    },
    {
      "epoch": 1.8793012175754367,
      "grad_norm": 0.22837461531162262,
      "learning_rate": 4.152941176470589e-06,
      "loss": 0.2066,
      "step": 3550
    },
    {
      "epoch": 1.9057702488088935,
      "grad_norm": 1.3145848512649536,
      "learning_rate": 4.054901960784315e-06,
      "loss": 0.1488,
      "step": 3600
    },
    {
      "epoch": 1.9322392800423505,
      "grad_norm": 60.913780212402344,
      "learning_rate": 3.95686274509804e-06,
      "loss": 0.2141,
      "step": 3650
    },
    {
      "epoch": 1.9587083112758075,
      "grad_norm": 0.4037637412548065,
      "learning_rate": 3.858823529411765e-06,
      "loss": 0.1893,
      "step": 3700
    },
    {
      "epoch": 1.9851773425092643,
      "grad_norm": 1.039204716682434,
      "learning_rate": 3.7607843137254907e-06,
      "loss": 0.1195,
      "step": 3750
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8726374570446735,
      "eval_f1": 0.870345841252772,
      "eval_loss": 0.5340990424156189,
      "eval_precision": 0.8760218465818764,
      "eval_recall": 0.8677489696281282,
      "eval_runtime": 9.3179,
      "eval_samples_per_second": 499.683,
      "eval_steps_per_second": 31.23,
      "step": 3778
    }
  ],
  "logging_steps": 50,
  "max_steps": 5667,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.815923807431885e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
